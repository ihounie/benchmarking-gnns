{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for preparing and saving MOLECULAR graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to DGL format and save with pickle"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 3,
>>>>>>> b22de18d594b91c11a1b339f6b81cd3d27d0e221
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "/home/hounie/dnai/benchmarking-gnns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nimport sys\\nsys.path.append(rootdir)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
=======
      "/home/vijay/graphdeeplearning/benchmarking-gnns\n"
     ]
>>>>>>> b22de18d594b91c11a1b339f6b81cd3d27d0e221
    }
   ],
   "source": [
    "import os\n",
<<<<<<< HEAD
    "rootdir = '../../'\n",
    "os.chdir(rootdir) # go to root folder of the project\n",
    "print(os.getcwd())\n",
    "'''\n",
    "import sys\n",
    "sys.path.append(rootdir)\n",
    "'''\n"
=======
    "os.chdir('../../') # go to root folder of the project\n",
    "print(os.getcwd())\n"
>>>>>>> b22de18d594b91c11a1b339f6b81cd3d27d0e221
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "from data.yeast import YeastDatasetDGL \n",
    "\n",
    "from data.data import LoadData\n",
    "from torch.utils.data import DataLoader\n",
    "from data.yeast import YeastDataset\n"
=======
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from data.yast import YeastDatasetDGL \n",
    "\n",
    "from data.data import LoadData\n",
    "from torch.utils.data import DataLoader\n",
    "from data.molecules import YeastDataset\n"
>>>>>>> b22de18d594b91c11a1b339f6b81cd3d27d0e221
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 5,
>>>>>>> b22de18d594b91c11a1b339f6b81cd3d27d0e221
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "preparing 665 graphs for the TRAIN set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hounie/dnai/benchmarking-gnns/data/yeast.py:49: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629427478/work/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  edge_list = (adj != 0).nonzero()  # converting adj matrix to edge_list\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating graph from sparse GSO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:00, 154.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of non-zero values in adj : 0.9999997853348609\n",
      "Graph Created in 0.7833936214447021s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "665it [00:03, 178.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing 118 graphs for the VAL set...\n",
      "Creating graph from sparse GSO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:00, 182.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of non-zero values in adj : 0.9999997853348609\n",
      "Graph Created in 0.7073132991790771s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "118it [00:00, 180.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing 196 graphs for the TEST set...\n",
      "Creating graph from sparse GSO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:00, 182.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of non-zero values in adj : 0.9999997853348609\n",
      "Graph Created in 0.7125287055969238s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "196it [00:01, 180.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 35.7519s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
=======
      "preparing 10000 graphs for the TRAIN set...\n",
      "preparing 1000 graphs for the VAL set...\n",
      "preparing 1000 graphs for the TEST set...\n",
      "Time taken: 84.0698s\n"
>>>>>>> b22de18d594b91c11a1b339f6b81cd3d27d0e221
     ]
    }
   ],
   "source": [
    "DATASET_NAME = 'YEAST'\n",
    "dataset = YeastDatasetDGL(DATASET_NAME) \n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 7,
>>>>>>> b22de18d594b91c11a1b339f6b81cd3d27d0e221
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "665\n",
      "118\n",
      "196\n",
      "(Graph(num_nodes=11623, num_edges=1350941,\n",
      "      ndata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}), tensor(-1.3988, dtype=torch.float64))\n",
      "(Graph(num_nodes=11623, num_edges=1350941,\n",
      "      ndata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}), tensor(6.1884, dtype=torch.float64))\n",
      "(Graph(num_nodes=11623, num_edges=1350941,\n",
      "      ndata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}), tensor(10.1645, dtype=torch.float64))\n"
=======
      "10000\n",
      "1000\n",
      "1000\n",
      "(DGLGraph(num_nodes=29, num_edges=64,\n",
      "         ndata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}\n",
      "         edata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}), tensor([0.8350]))\n",
      "(DGLGraph(num_nodes=35, num_edges=78,\n",
      "         ndata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}\n",
      "         edata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}), tensor([0.6299]))\n",
      "(DGLGraph(num_nodes=16, num_edges=34,\n",
      "         ndata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}\n",
      "         edata_schemes={'feat': Scheme(shape=(), dtype=torch.int64)}), tensor([1.9973]))\n"
>>>>>>> b22de18d594b91c11a1b339f6b81cd3d27d0e221
     ]
    }
   ],
   "source": [
    "print(len(dataset.train))\n",
    "print(len(dataset.val))\n",
    "print(len(dataset.test))\n",
    "\n",
    "print(dataset.train[0])\n",
    "print(dataset.val[0])\n",
    "print(dataset.test[0])\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "start = time.time()\n",
    "f='data/yeast/YEAST'\n",
    "joblib.dump([dataset.train,dataset.val,dataset.test],f+'.gz', compress=1)\n",
    "print('Time (sec):',time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "start = time.time()\n",
    "f='data/yeast/YEAST'\n",
    "joblib.dump([dataset.train,dataset.val,dataset.test],f)\n",
    "print('Time (sec):',time.time() - start)"
=======
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (sec): 6.659376859664917\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "with open('data/yeast/YEAST.pkl','wb') as f:\n",
    "        pickle.dump([dataset.train,dataset.val,dataset.test],f)\n",
    "print('Time (sec):',time.time() - start)\n"
>>>>>>> b22de18d594b91c11a1b339f6b81cd3d27d0e221
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test load function"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] Loading dataset ZINC...\n",
      "train, test, val sizes : 10000 1000 1000\n",
      "[I] Finished loading.\n",
      "[I] Data load time: 8.5329s\n"
     ]
    }
   ],
>>>>>>> b22de18d594b91c11a1b339f6b81cd3d27d0e221
   "source": [
    "DATASET_NAME = 'YEAST'\n",
    "dataset = LoadData(DATASET_NAME)\n",
    "trainset, valset, testset = dataset.train, dataset.val, dataset.test\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "collate = YeastDataset.collate\n",
    "print(YeastDataset)\n",
=======
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'data.molecules.MoleculeDataset'>\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "collate = MoleculeDataset.collate\n",
    "print(MoleculeDataset)\n",
>>>>>>> b22de18d594b91c11a1b339f6b81cd3d27d0e221
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, collate_fn=collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
<<<<<<< HEAD
=======
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
>>>>>>> b22de18d594b91c11a1b339f6b81cd3d27d0e221
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
